{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e90dbd-0794-4e73-901f-725b11707096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "import random\n",
    "# Set seed for reproducibility\n",
    "seed = 2542\n",
    "random.seed(seed)\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad3e5705-8d0d-4412-9d7e-7485e0c81834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() #check for CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5305f11-4fc7-47bd-8d88-089cbda01b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to ../data/external/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the custom NLTK data directory\n",
    "nltk_data_dir = '../data/external/'\n",
    "if not os.path.exists(nltk_data_dir):\n",
    "    os.makedirs(nltk_data_dir)\n",
    "nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Download the stopwords into the specified directory\n",
    "nltk.download('stopwords', download_dir=nltk_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f2cc2-1fa0-4d76-be05-90592449c000",
   "metadata": {},
   "source": [
    "#### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff460e68-791f-4410-bc25-77b11d406c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2e49c4-92e9-4160-a34a-17532e769337",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/raw/tiny-shakespeare.txt', 'r') as file:\n",
    "    # Read the entire file content as a single string\n",
    "    words = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76703add-3125-43c2-8b6c-bc24f2b895a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into words\n",
    "# Remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "words = words.translate(translator)\n",
    "\n",
    "words = words.lower().split()\n",
    "\n",
    "# Remove stopwords and punctuation\n",
    "cleaned_words = [word for word in words if word.lower() not in stop_words and word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "108e1bc4-f9aa-4bb0-8302-41addedb9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set(cleaned_words))\n",
    "\n",
    "# Initialize the word_to_ix dictionary\n",
    "word_to_ix = {word: idx for idx, word in enumerate(unique_words)}\n",
    "\n",
    "# Initialize the ix_to_word dictionary by inverting word_to_ix\n",
    "ix_to_word = {idx: word for word, idx in word_to_ix.items()}\n",
    "\n",
    "cleaned_words_to_ix = [word_to_ix[word] for word in cleaned_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7f0156-7886-495c-b8c1-31a695a0c9fb",
   "metadata": {},
   "source": [
    "#### Dataset Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efb0261f-1a54-49cb-a066-cff8e105724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12718\n"
     ]
    }
   ],
   "source": [
    "vocab_length = len(unique_words) #12178\n",
    "print(vocab_length)\n",
    "\n",
    "context_window = 2 #each side\n",
    "n_negatives = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90f048-7a01-4f11-9736-607f54fcdee7",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c839ea-ae58-4824-bf50-aea50497d02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/81939 [00:00<?, ?it/s]/tmp/ipykernel_8429/2402477000.py:16: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  negative_sample_indexes = random.sample(negative_sample_set, n_negatives)\n",
      "100%|███████████████████████████████████| 81939/81939 [00:11<00:00, 7351.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "vocab_set = set(word_to_ix.values())\n",
    "\n",
    "for text_index in tqdm(range(vocab_length, len(cleaned_words) - vocab_length)):\n",
    "    center_word_indexes = [cleaned_words_to_ix[text_index]]# * (2 * context_window)\n",
    "    \n",
    "    context_word_indexes = [\n",
    "        cleaned_words_to_ix[text_index - context_index] \n",
    "        for context_index in range(1, context_window + 1)\n",
    "    ] + [\n",
    "        cleaned_words_to_ix[text_index + context_index] \n",
    "        for context_index in range(1, context_window + 1)\n",
    "    ]\n",
    "    \n",
    "    negative_sample_set = vocab_set - set(context_word_indexes)\n",
    "    negative_sample_indexes = random.sample(negative_sample_set, n_negatives)\n",
    "\n",
    "    dataset.append([center_word_indexes, context_word_indexes, negative_sample_indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89832728-c7e9-4191-8139-4bc8a993ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6202], [8689, 1146, 4299, 991], [1034, 1112, 10359, 2202]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c87ac88-67a0-49bb-8593-830c49ef434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataset class for data loader\n",
    "class Word2VecDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        center_word_indexes, context_word_indexes, negative_sample_indexes = self.data[idx]\n",
    "        return (\n",
    "            torch.tensor(center_word_indexes, dtype=torch.long),\n",
    "            torch.tensor(context_word_indexes, dtype=torch.long),\n",
    "            torch.tensor(negative_sample_indexes, dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1ea96-70d9-4340-b240-d585414319f5",
   "metadata": {},
   "source": [
    "#### Word2Vec Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e098e347-0366-489a-b34a-8865bdd17b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(nn.Module):\n",
    "    def __init__(self, vocab_length, vector_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # Vector Embeddings\n",
    "        self.center_embeddings = nn.Embedding(vocab_length, vector_length)\n",
    "        self.context_embeddings = nn.Embedding(vocab_length, vector_length)\n",
    "        \n",
    "        # Move all model parameters to GPU if available\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, center_indices, context_indices, negative_indices):\n",
    "        # Get embeddings\n",
    "        center_embeddings = self.center_embeddings(center_indices)  \n",
    "        context_embeddings = self.context_embeddings(context_indices)  \n",
    "        negative_embeddings = self.context_embeddings(negative_indices)  \n",
    "\n",
    "        # Compute dot product for positive pairs\n",
    "        positive_dot_products = torch.bmm(center_embeddings, context_embeddings.transpose(1, 2)).squeeze(1)  \n",
    "\n",
    "        # Compute dot product for negative pairs\n",
    "        negative_dot_products = torch.bmm(center_embeddings, negative_embeddings.transpose(1, 2)).squeeze(1)  \n",
    "\n",
    "        return positive_dot_products, negative_dot_products\n",
    "\n",
    "embedding_dim = 100  # Length of word vector\n",
    "word2vec_model = Word2Vec(vocab_length, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "336707ba-9496-45c6-8717-7c5776e20599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Wrap the data_loader with tqdm to show the progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=f'Epoch {epoch}', leave=False)\n",
    "    \n",
    "    for center_indices, context_indices, negative_indices in progress_bar:\n",
    "        print(center_indices.shape)\n",
    "        center_indices, context_indices, negative_indices = center_indices.to(device), context_indices.to(device), negative_indices.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        pos_scores, neg_scores = model(center_indices, context_indices, negative_indices)\n",
    "        \n",
    "        # True labels - 1s for positive samples, 0s for negative samples\n",
    "        positive_labels = torch.ones_like(pos_scores)\n",
    "        negative_labels = torch.zeros_like(neg_scores)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss_pos = criterion(pos_scores, positive_labels)\n",
    "        loss_neg = criterion(neg_scores, negative_labels)\n",
    "        loss = loss_pos + loss_neg\n",
    "        \n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9d58e71-c34f-40d9-b908-2f8e601f44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the word2vec dataset and DataLoader\n",
    "word2vec_dataset = Word2VecDataset(dataset)\n",
    "batch_size = 256 # You can adjust the batch size according to your needs\n",
    "data_loader = DataLoader(word2vec_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#Model Hyperparameters\n",
    "lr = 1e-4\n",
    "\n",
    "optimizer = torch.optim.Adam(word2vec_model.parameters(), lr=lr)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#Epochs\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410513aa-a2b4-4f51-97e3-7f5cb661209a",
   "metadata": {},
   "source": [
    "#### Notes to self\n",
    "\n",
    "#### Look at PyTorch Broadcasting Documentation -> \\<operation> a row vector to all rows in a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8242982-1f3c-447e-826f-493b0bbc9f60",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "202c784d-1359-4404-98e8-67183d1cd5d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|███▍                            | 35/321 [00:00<00:01, 175.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  24%|███████▋                        | 77/321 [00:00<00:01, 196.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  37%|███████████▍                   | 119/321 [00:00<00:00, 203.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  50%|███████████████▌               | 161/321 [00:00<00:00, 201.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  57%|█████████████████▌             | 182/321 [00:00<00:00, 194.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  69%|█████████████████████▌         | 223/321 [00:01<00:00, 194.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  83%|█████████████████████████▌     | 265/321 [00:01<00:00, 200.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([256, 1])\n",
      "torch.Size([19, 1])\n",
      "Epoch 0: Loss 2561.9285049438477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved new best model with loss: 2561.9285049438477\n"
     ]
    }
   ],
   "source": [
    "lowest_loss = float('inf')\n",
    "\n",
    "#for epoch in range(epochs):\n",
    "for epoch in range(1):\n",
    "    it_loss = train(model=word2vec_model, data_loader=data_loader, optimizer=optimizer, criterion=criterion,\n",
    "                    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), epoch=epoch)\n",
    "    print(f\"Epoch {epoch}: Loss {it_loss}\")\n",
    "\n",
    "    # Check if the current epoch's loss is the lowest and save the model\n",
    "    if it_loss < lowest_loss:\n",
    "        lowest_loss = it_loss\n",
    "        torch.save(word2vec_model.state_dict(), '../models/word2vec/best_model.pth')\n",
    "        print(f\"Saved new best model with loss: {lowest_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3913dd0-68f0-47c5-b517-706e8c97592d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
